<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>NVIDIA Generative AI Examples &mdash; NVIDIA Generative AI Examples 0.5.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/version.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Support Matrix" href="support-matrix.html" />
 


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >


<a href="#">
  <img src="_static/nvidia-logo-white.png" class="logo" alt="Logo"/>
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">RAG Pipelines for Developers</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">About the RAG Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="support-matrix.html">Support Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="ai-foundation-models.html">AI Foundation Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="local-gpu.html">Local GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-gpu.html">Multi-GPU for Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="query-decomposition.html">Query Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantized-llm-model.html">Quantized Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="structured-data.html">Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="multimodal-data.html">Multimodal Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi-turn.html">Multi-turn</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-sample-web-application.html">Sample Chat Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="vector-database.html">Alternative Vector Database</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="observability.html">Observability</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Jupyter Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/00-llm-non-streaming-nemotron.html">Basics: Prompt, Client, and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/01-llm-streaming-client.html">LLM Streaming Client</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/02_langchain_simple.html">Q&amp;A with LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/03_llama_index_simple.html">Q&amp;A with LlamaIndex</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/04_llamaindex_hier_node_parser.html">Advanced Q&amp;A with LlamaIndex</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/05_dataloader.html">Press Release Chat Bot</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/07_Option%281%29_NVIDIA_AI_endpoint_simple.html">NVIDIA AI Endpoints with LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/07_Option%282%29_minimalistic_RAG_with_langchain_local_HF_LLM.html">LangChain with Local Llama 2 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/08_Option%281%29_llama_index_with_NVIDIA_AI_endpoint.html">NVIDIA AI Endpoints, LlamaIndex, and LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/08_Option%282%29_llama_index_with_HF_local_LLM.html">HF Checkpoints with LlamaIndex and LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/09_Agent_use_tools_leveraging_NVIDIA_AI_endpoints.html">Multimodal Models from NVIDIA AI Endpoints with LangChain Agent</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm-inference-server.html">NeMo Framework Inference Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="frontend.html">RAG Playground Web Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="jupyter-server.html">Jupyter Notebook Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="chain-server.html">Chain Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Software Component Configuration</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">NVIDIA Generative AI Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
      <li>NVIDIA Generative AI Examples</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <!--
  SPDX-FileCopyrightText: Copyright (c) 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  SPDX-License-Identifier: Apache-2.0

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<section id="nvidia-generative-ai-examples">
<h1>NVIDIA Generative AI Examples<a class="headerlink" href="#nvidia-generative-ai-examples" title="Permalink to this headline"></a></h1>
<p>A small change.</p>
<p>Generative AI enables users to quickly generate new content based on a variety of inputs and is a powerful tool for streamlining the workflow of creatives, engineers, researchers, scientists, and more.
The use cases and possibilities span all industries and individuals.
Generative AI models can produce novel content like stories, emails, music, images, and videos.</p>
<p>Generative AI starts with foundational models trained on vast quantities of unlabeled data.
Large language models (LLMs) are trained on an extensive range of textual data online.
These LLMs can understand prompts and generate novel, human-like responses.
Businesses can build applications to leverage this capability of LLMs.
Some uses are creative writing assistants for marketing, document summarization for legal teams, and code writing for software development.</p>
<p>The NVIDIA Generative AI Examples use Docker Compose
run Retrieval Augmented Generation (RAG) Large Language Model (LLM) pipelines.</p>
<p>All the example pipelines deploy a sample chat bot application for question and answering that is enhanced with RAG.
The chat bot also supports uploading documents to create a knowledge base.</p>
<section id="developer-rag-examples">
<h2>Developer RAG Examples<a class="headerlink" href="#developer-rag-examples" title="Permalink to this headline"></a></h2>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><div class="line-block">
<div class="line">Model</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Embedding</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Framework</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Description</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Multi-GPU</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">TensorRT-LLM</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">NVIDIA AI</div>
<div class="line">Foundation</div>
<div class="line">Models and</div>
<div class="line">Endpoints</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Triton</div>
<div class="line">Inference</div>
<div class="line">Server</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Vector</div>
<div class="line">Database</div>
</div>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>mixtral_8x7b</p></td>
<td><p>nvolveqa_40k</p></td>
<td><p>LangChain</p></td>
<td><p><a class="reference internal" href="ai-foundation-models.html"><span class="doc">Using the NVIDIA AI Foundation Models</span></a></p></td>
<td><p>NO</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
<tr class="row-odd"><td><p>llama-2</p></td>
<td><p>e5-large-v2</p></td>
<td><p>LlamaIndex</p></td>
<td><p><a class="reference internal" href="local-gpu.html"><span class="doc">Using Local GPUs for a Q&amp;A Chatbot</span></a></p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
<tr class="row-even"><td><p>llama-2</p></td>
<td><p>e5-large-v2</p></td>
<td><p>LlamaIndex</p></td>
<td><p><a class="reference internal" href="multi-gpu.html"><span class="doc">Multi-GPU for Inference</span></a></p></td>
<td><p>YES</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
<tr class="row-odd"><td><p>llama2_70b</p></td>
<td><p>nvolveqa_40k</p></td>
<td><p>LangChain</p></td>
<td><p><a class="reference internal" href="query-decomposition.html"><span class="doc">Query Decomposition</span></a></p></td>
<td><p>NO</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
<tr class="row-even"><td><p>llama2_7b</p></td>
<td><p>e5-large-v2</p></td>
<td><p>LlamaIndex</p></td>
<td><p><a class="reference internal" href="quantized-llm-model.html"><span class="doc">Quantized LLM Inference Model</span></a></p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
<tr class="row-odd"><td><p>NV-Llama2-70B-RLHF</p></td>
<td><p>Not Applicable</p></td>
<td><p>PandasAI</p></td>
<td><p><a class="reference internal" href="structured-data.html"><span class="doc">Structured Data</span></a></p></td>
<td><p>NO</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>Not Applicable</p></td>
</tr>
<tr class="row-even"><td><div class="line-block">
<div class="line">mixtral_8x7b for response generation,</div>
<div class="line">deplot for graph to text conversion,</div>
<div class="line">neva_22B for image to text conversion</div>
</div>
</td>
<td><p>nvolveqa_40k</p></td>
<td><p>Custom Python</p></td>
<td><p><a class="reference internal" href="multimodal-data.html"><span class="doc">Multimodal Data</span></a></p></td>
<td><p>NO</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
<tr class="row-odd"><td><p>mixtral_8x7b</p></td>
<td><p>nvolveqa_40k</p></td>
<td><p>LangChain</p></td>
<td><p><a class="reference internal" href="multi-turn.html"><span class="doc">Multi-Turn Conversational Chat Bot</span></a></p></td>
<td><p>NO</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>Milvus or pgvector</p></td>
</tr>
</tbody>
</table>
</section>
<section id="open-source-connectors">
<h2>Open Source Connectors<a class="headerlink" href="#open-source-connectors" title="Permalink to this headline"></a></h2>
<p>These are open source connectors for NVIDIA-hosted and self-hosted API endpoints. These open source connectors are maintained and tested by NVIDIA engineers.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Framework</p></th>
<th class="head"><p>Chat</p></th>
<th class="head"><p>Text Embedding</p></th>
<th class="head"><p>Python</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://python.langchain.com/docs/integrations/providers/nvidia">NVIDIA AI Foundation Endpoints</a></p></td>
<td><p><a class="reference external" href="https://www.langchain.com/">Langchain</a></p></td>
<td><p><a class="reference external" href="https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints">YES</a></p></td>
<td><p><a class="reference external" href="https://python.langchain.com/docs/integrations/text_embedding/nvidia_ai_endpoints">YES</a></p></td>
<td><p><a class="reference external" href="https://pypi.org/project/langchain-nvidia-ai-endpoints/">YES</a></p></td>
<td><p>Easy access to NVIDIA hosted models. Supports chat, embedding, code generation, steerLM, multimodal, and RAG.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://github.com/langchain-ai/langchain/tree/master/libs/partners/nvidia-trt">NVIDIA Triton + TensorRT-LLM</a></p></td>
<td><p><a class="reference external" href="https://www.langchain.com/">Langchain</a></p></td>
<td><p><a class="reference external" href="https://github.com/langchain-ai/langchain/blob/master/libs/partners/nvidia-trt/docs/llms.ipynb">YES</a></p></td>
<td><p><a class="reference external" href="https://github.com/langchain-ai/langchain/blob/master/libs/partners/nvidia-trt/docs/llms.ipynb">YES</a></p></td>
<td><p><a class="reference external" href="https://pypi.org/project/langchain-nvidia-trt/">YES</a></p></td>
<td><p>This connector allows Langchain to remotely interact with a Triton inference server over GRPC or HTTP tfor optimized LLM inference.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://docs.llamaindex.ai/en/stable/examples/llm/nvidia_triton.html">NVIDIA Triton Inference Server</a></p></td>
<td><p><a class="reference external" href="https://www.llamaindex.ai/">LlamaIndex</a></p></td>
<td><p>YES</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>Triton inference server provides API access to hosted LLM models over gRPC.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://docs.llamaindex.ai/en/stable/examples/llm/nvidia_tensorrt.html">NVIDIA TensorRT-LLM</a></p></td>
<td><p><a class="reference external" href="https://www.llamaindex.ai/">LlamaIndex</a></p></td>
<td><p>YES</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
<td><p>TensorRT-LLM provides a Python API to build TensorRT engines with state-of-the-art optimizations for LLM inference on NVIDIA GPUs.</p></td>
</tr>
</tbody>
</table>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="support-matrix.html" class="btn btn-neutral float-right" title="Support Matrix" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 



</body>
</html>